# 5-3-2 特征向量的性质

#线性代数 #特征向量 #性质定理 #线性无关 #数学二 #考研数学

## 📌 知识点概述

特征向量作为特征值理论的另一个核心概念，具有许多独特而重要的性质。这些性质不仅揭示了特征向量的内在结构，还为矩阵对角化、正交化等重要应用提供了理论基础。深入理解特征向量的性质，对掌握整个特征值理论至关重要。

## 📝 基本性质

### 1. 特征向量的非零性和齐次性

**性质1**：
- 特征向量必须是非零向量
- 若 $x$ 是特征向量，则 $kx$（$k \neq 0$）也是对应于同一特征值的特征向量

**理解**：
- 零向量不能作为特征向量（定义要求）
- 特征向量的方向是本质的，长度可以任意缩放

### 2. 不同特征值对应的特征向量线性无关

**定理1**：设 $\lambda_1, \lambda_2, \ldots, \lambda_k$ 是矩阵 $A$ 的 $k$ 个互不相同的特征值，$x_1, x_2, \ldots, x_k$ 是对应的特征向量，则 $x_1, x_2, \ldots, x_k$ 线性无关。

**证明**（数学归纳法）：
1. $k = 1$ 时，单个特征向量非零，故线性无关

2. 假设对 $k-1$ 成立，证明对 $k$ 成立
   
   设 $c_1x_1 + c_2x_2 + \cdots + c_kx_k = 0$ ... (1)
   
   两边左乘 $A$：
   $c_1Ax_1 + c_2Ax_2 + \cdots + c_kAx_k = 0$
   $c_1\lambda_1x_1 + c_2\lambda_2x_2 + \cdots + c_k\lambda_kx_k = 0$ ... (2)
   
   $(2) - \lambda_k \times (1)$：
   $c_1(\lambda_1 - \lambda_k)x_1 + c_2(\lambda_2 - \lambda_k)x_2 + \cdots + c_{k-1}(\lambda_{k-1} - \lambda_k)x_{k-1} = 0$
   
   由归纳假设，$x_1, x_2, \ldots, x_{k-1}$ 线性无关，且 $\lambda_i - \lambda_k \neq 0$（$i < k$）
   
   所以 $c_1 = c_2 = \cdots = c_{k-1} = 0$
   
   代入(1)得 $c_kx_k = 0$，由于 $x_k \neq 0$，所以 $c_k = 0$

### 3. 同一特征值的特征向量构成子空间

**定理2**：矩阵 $A$ 对应于特征值 $\lambda$ 的所有特征向量，连同零向量一起，构成一个子空间，称为特征子空间，记作 $V_\lambda$。

**证明**：
设 $x_1, x_2 \in V_\lambda$（非零），即 $Ax_1 = \lambda x_1$，$Ax_2 = \lambda x_2$

1. 对加法封闭：$A(x_1 + x_2) = Ax_1 + Ax_2 = \lambda x_1 + \lambda x_2 = \lambda(x_1 + x_2)$
2. 对数乘封闭：$A(kx_1) = kAx_1 = k\lambda x_1 = \lambda(kx_1)$

因此 $V_\lambda$ 是向量空间的子空间。

### 4. 特征向量与矩阵运算

**性质2**：设 $x$ 是矩阵 $A$ 对应于特征值 $\lambda$ 的特征向量，则：

1. $x$ 是 $A^k$ 对应于特征值 $\lambda^k$ 的特征向量
2. 若 $A$ 可逆，$x$ 是 $A^{-1}$ 对应于特征值 $\lambda^{-1}$ 的特征向量
3. $x$ 是 $aA + bE$ 对应于特征值 $a\lambda + b$ 的特征向量
4. 一般地，对多项式 $p(t) = a_nt^n + \cdots + a_1t + a_0$，$x$ 是 $p(A)$ 对应于特征值 $p(\lambda)$ 的特征向量

**证明示例**（对于 $A^k$）：
$$A^kx = A^{k-1}(Ax) = A^{k-1}(\lambda x) = \lambda A^{k-1}x = \cdots = \lambda^k x$$

## 🎯 重要定理

### 1. 特征向量的正交性（实对称矩阵）

**定理3**：实对称矩阵不同特征值对应的特征向量相互正交。

**证明**：
设 $A$ 是实对称矩阵，$\lambda_1 \neq \lambda_2$ 是两个特征值，$x_1, x_2$ 是对应的特征向量。

$$\lambda_1(x_1^Tx_2) = (Ax_1)^Tx_2 = x_1^TA^Tx_2 = x_1^TAx_2 = x_1^T(\lambda_2x_2) = \lambda_2(x_1^Tx_2)$$

由于 $\lambda_1 \neq \lambda_2$，所以 $x_1^Tx_2 = 0$，即 $x_1 \perp x_2$。

### 2. 特征向量的个数与重数

**定理4**：设 $\lambda$ 是矩阵 $A$ 的特征值：
- **几何重数**：对应特征子空间 $V_\lambda$ 的维数，即线性无关特征向量的最大个数
- **代数重数**：$\lambda$ 作为特征多项式根的重数
- 关系：$1 \leq$ 几何重数 $\leq$ 代数重数

### 3. 特征向量的完备性

**定理5**：$n$ 阶矩阵 $A$ 有 $n$ 个线性无关的特征向量的充要条件是 $A$ 可对角化。

这是矩阵对角化理论的基础。

## 💡 特征向量的计算性质

### 1. 求解特征向量

对应于特征值 $\lambda$ 的特征向量是齐次方程组 $(A - \lambda E)x = 0$ 的非零解。

### 2. 特征向量的标准化

任意特征向量 $x$ 可以标准化为单位向量：$\hat{x} = \frac{x}{||x||}$

### 3. 特征向量的选取

同一特征值的特征向量不唯一，通常选择：
- 单位向量
- 整数分量向量
- 某个分量为1的向量

## 📐 典型例题

### 例1：验证线性无关性

设矩阵 $A$ 的特征值为 $\lambda_1 = 1, \lambda_2 = 2, \lambda_3 = 3$，对应的特征向量为：
$$x_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, x_2 = \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}, x_3 = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$$

验证 $x_1, x_2, x_3$ 线性无关。

**解**：
方法1：根据定理，不同特征值对应的特征向量线性无关。

方法2：直接验证
$$\begin{vmatrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{vmatrix} = 1 \neq 0$$

所以 $x_1, x_2, x_3$ 线性无关。

### 例2：特征子空间

设 $A = \begin{pmatrix} 2 & 1 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 3 \end{pmatrix}$，求特征值 $\lambda = 2$ 对应的特征子空间。

**解**：
求解 $(A - 2E)x = 0$：
$$\begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}\begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}$$

得到：$x_2 = 0, x_3 = 0, x_1$ 任意

特征子空间：$V_2 = \text{span}\left\{\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}\right\}$

维数为1（几何重数 = 1），而代数重数 = 2。

### 例3：实对称矩阵的正交特征向量

设实对称矩阵 $A = \begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix}$，求其特征向量并验证正交性。

**解**：
1. 特征值：$\lambda_1 = 3, \lambda_2 = -1$

2. 特征向量：
   - $\lambda_1 = 3$：$x_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}$
   - $\lambda_2 = -1$：$x_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$

3. 验证正交性：
   $x_1^Tx_2 = 1 \times 1 + 1 \times (-1) = 0$ ✓

## 🔍 深入理解

### 1. 特征向量的几何意义
- 表示在线性变换下方向不变的向量
- 特征值表示沿该方向的伸缩倍数
- 特征子空间是所有不变方向的集合

### 2. 特征向量与线性变换
- 特征向量揭示了线性变换的"主方向"
- 在这些方向上，变换简化为标量乘法
- 这是理解线性变换本质的关键

### 3. 特征向量的应用
- **主成分分析**：找到数据的主要方向
- **振动分析**：确定系统的振动模态
- **图像处理**：特征脸识别
- **网络分析**：PageRank算法

## 📚 易错提醒

### 1. 特征向量的唯一性
- 特征向量不唯一（可以缩放）
- 但特征子空间是唯一的
- 标准化可以得到唯一的单位特征向量

### 2. 零特征值的特征向量
- $\lambda = 0$ 对应的特征向量仍然非零
- 这些特征向量构成核空间 $N(A)$
- 不要混淆特征值为0和特征向量为0

### 3. 重根情况
- 重根可能对应多个线性无关的特征向量
- 也可能只有一个（几何重数 < 代数重数）
- 这决定了矩阵是否可对角化

### 4. 复特征向量
- 实矩阵可能有复特征向量
- 复特征向量对实际问题的解释需要特别注意

## 🏷️ 标签体系

- **L1知识点**：`特征向量性质` `线性无关性` `特征子空间` `正交性`
- **L2方法**：`特征向量求解` `正交化` `标准化`
- **L3章节**：`第五章特征值与特征向量`
- **难度**：`medium`

## 🔗 相关链接

- [[5-1-1 特征值与特征向量的定义]]：基本概念
- [[5-3-1 特征值的基本性质]]：特征值的相关性质
- [[5-4-3 矩阵的对角化条件]]：特征向量完备性的应用
- [[3-6-4 施密特正交化方法]]：特征向量的正交化

---

*特征向量——揭示线性变换本质方向的数学工具！*